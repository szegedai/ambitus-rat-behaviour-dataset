# Import core libraries
import pandas as pd
import numpy as np
import datetime
# Set random seed for reproducibility
np.random.seed(42)





#Helper functions
def gen_id(data):
    """Create a unique identifier from group, number, generation.

    Args:
        data (pd.DataFrame): raw data
    Returns:
        pd.DataFrame: data with an additional 'id' column
    """
    data['id'] = data['Group'].astype(str) + '_' + data['NR'].astype(str) + '_' + data['Generation'].astype(str)
    return data

def make_rat_one_row(data):
    """From 4 trials converts each rat into a single row.

    Args:
        data (pd.DataFrame): raw data
    Returns:
        pd.DataFrame: data with each rat as a single row
    """
    re_df = pd.DataFrame()
    for id in data['id'].unique():
        temp = data[data['id'] == id]
        to_merge = temp.loc[temp['Trials'] == 1]
        for i in range(2, 5):
            tmp = temp.loc[temp['Trials'] == i].drop(columns=params['no_merge_cols'])
            to_merge = pd.merge(to_merge, tmp, how='inner', on="id", suffixes=('', f'_{i}'))

        re_df = pd.concat([re_df, to_merge], ignore_index=True)
    return re_df
        





params = {
    #Original data path
    'data' : '../raw/ambitus_0_15_log_29_07_2025.parquet',
    #Columns from the original dataset that are not needed for the analysis 
    'to_drop_cols' : ['Separation', 'Date_Ambitus', 'GR_Sex', 'G_S', 'Animal', 'EAT_E_Nr', 'EAT_I_Nr', 'EAT_TOT_Nr', 'Expl_E_BEF_Nr', 'Expl_I_BEF_Nr', 'Expl_E_I_BEF_Nr', 'Expl_E_AFT_Nr', 'Expl_I_AFT_Nr', 
                      'Expl_E_I_AFT_Nr', 'Expl_E_BEF_T', 'Expl_I_BEF_T', 'Expl_E_I_BEF_T', 'Expl_E_AFT_T', 'Expl_I_AFT_T', 'Expl_E_I_AFT_T', 'LAT_E', 'LAT_I', 'LAT_E_I', 'Expl_REP_E_BEF_Nr', 'Expl_REP_I_BEF_Nr',
                      'Expl_REP_BEF_Nr', 'Expl_REP_E_AFT_Nr', 'Expl_REP_I_AFT_Nr', 'Expl_REP_AFT_Nr', 'LOCO_BEF', 'L_C_Tot',
                      'Expl_E_AFT_T_Calc','Expl_I_AFT_T_Calc','Expl_E_I_AFT_T_Calc','Expl_E_BEF_Calc_T','Expl_I_BEF_Calc_T','Expl_E_I_BEF_Calc_T','Expl_E_AFT_Calc','Expl_I_AFT_Calc','Expl_E_I_AFT_Calc',
                      'Expl_REP_E_AFT_Nr_Calc',	'Expl_REP_I_AFT_Nr_Calc',	'Expl_REP_AFT_Nr_Calc'],
    'no_merge_cols': ['Group', 'NR', 'Generation', 'Trials', 'Paradigm'],
    'save_date':'29_07_2025'
}





parquet_data = pd.read_parquet(params['data'])
parquet_data = gen_id(parquet_data)
parquet_data





# Remove unnecessary columns based on the parameter list
parquet_data = parquet_data.drop(columns=params['to_drop_cols'])
# Transform the dataset so that each rat is represented by a single row
one_rowed_data = make_rat_one_row(parquet_data)
# Optionally standardize column names or values
one_rowed_data = one_rowed_data.replace('male', 'Male')
one_rowed_data = one_rowed_data.replace('female', 'Female')
one_rowed_data = one_rowed_data.fillna(-1)
one_rowed_data





#Drop columns that are not needed for the analysis
columns_to_drop = one_rowed_data.filter(regex='Group_|Sex_|Season_|Trials_|NR_|Year_|Paradigm_|Generation_|Unnamed').columns
one_rowed_data = one_rowed_data.drop(columns=columns_to_drop)
#Drop columns that are only contains -1 values
one_rowed_data = one_rowed_data.loc[:, (one_rowed_data != -1).any(axis=0)]
one_rowed_data





# Drop the 'Trials' column if it's no longer relevant
one_rowed_data.drop(columns=['Trials'], inplace=True)
# Save the cleaned and flattened dataset to CSV with timestamp
date = params['save_date']
one_rowed_data.to_csv(f"processed/ambitus_0_15_ml_ready_{date}.csv", index=False)



