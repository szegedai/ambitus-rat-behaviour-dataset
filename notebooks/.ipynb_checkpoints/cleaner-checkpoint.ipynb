{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def gen_id(data):\n",
    "    \"\"\"Create a unique identifier from group, number, generation.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): raw data\n",
    "    Returns:\n",
    "        pd.DataFrame: data with an additional 'id' column\n",
    "    \"\"\"\n",
    "    data['id'] = data['Group'].astype(str) + '_' + data['NR'].astype(str) + '_' + data['Generation'].astype(str)\n",
    "    return data\n",
    "\n",
    "def make_rat_one_row(data):\n",
    "    \"\"\"From 4 trials converts each rat into a single row.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): raw data\n",
    "    Returns:\n",
    "        pd.DataFrame: data with each rat as a single row\n",
    "    \"\"\"\n",
    "    re_df = pd.DataFrame()\n",
    "    for id in data['id'].unique():\n",
    "        temp = data[data['id'] == id]\n",
    "        to_merge = temp.loc[temp['Trials'] == 1]\n",
    "        for i in range(2, 5):\n",
    "            tmp = temp.loc[temp['Trials'] == i].drop(columns=params['no_merge_cols'])\n",
    "            to_merge = pd.merge(to_merge, tmp, how='inner', on=\"id\", suffixes=('', f'_{i}'))\n",
    "\n",
    "        re_df = pd.concat([re_df, to_merge], ignore_index=True)\n",
    "    return re_df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Parameters\n",
    "This dictionary defines:\n",
    "- The path to the raw dataset\n",
    "- Columns to drop during the cleaning process\n",
    "- String-based columns that should be standardized to lowercase\n",
    "\n",
    "These parameters make the cleaning functions reusable and adaptable to other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    #Original data path\n",
    "    'data' : 'raw/ambitus_0_15_log_24_07_2025.parquet',\n",
    "    #Columns from the original dataset that are not needed for the analysis \n",
    "    'to_drop_cols' : ['Separation', 'Date_Ambitus', 'GR_Gender', 'G_S', 'Animal', 'EAT_E_Nr', 'EAT_I_Nr', 'EAT_TOT_Nr', 'Expl_E_BEF_Nr', 'Expl_I_BEF_Nr', 'Expl_E_I_BEF_Nr', 'Expl_E_AFT_Nr', 'Expl_I_AFT_Nr', \n",
    "                      'Expl_E_I_AFT_Nr', 'Expl_E_BEF_T', 'Expl_I_BEF_T', 'Expl_E_I_BEF_T', 'Expl_E_AFT_T', 'Expl_I_AFT_T', 'Expl_E_I_AFT_T', 'LAT_E', 'LAT_I', 'LAT_E_I', 'Expl_REP_E_BEF_Nr', 'Expl_REP_I_BEF_Nr',\n",
    "                      'Expl_REP_BEF_Nr', 'Expl_REP_E_AFT_Nr', 'Expl_REP_I_AFT_Nr', 'Expl_REP_AFT_Nr', 'LOCO_BEF', 'L_C_Tot',\n",
    "                      'Expl_E_AFT_T_Calc','Expl_I_AFT_T_Calc','Expl_E_I_AFT_T_Calc','Expl_E_BEF_Calc_T','Expl_I_BEF_Calc_T','Expl_E_I_BEF_Calc_T','Expl_E_AFT_Calc','Expl_I_AFT_Calc','Expl_E_I_AFT_Calc',\n",
    "                      'Expl_REP_E_AFT_Nr_Calc',\t'Expl_REP_I_AFT_Nr_Calc',\t'Expl_REP_AFT_Nr_Calc'],\n",
    "    'no_merge_cols': ['Group', 'NR', 'Generation', 'Trials', 'Paradigm']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Annotate the Raw Dataset\n",
    "We load the raw data from the specified parquet file and apply the gen_id() function to add a unique identifier (id) for each animal. This step prepares the data for downstream cleaning and ensures consistent identification of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Season</th>\n",
       "      <th>Separation</th>\n",
       "      <th>G_S</th>\n",
       "      <th>Paradigm</th>\n",
       "      <th>Date_Ambitus</th>\n",
       "      <th>Year</th>\n",
       "      <th>NR</th>\n",
       "      <th>Group</th>\n",
       "      <th>...</th>\n",
       "      <th>Expl_I_BEF_Loco_ratio</th>\n",
       "      <th>Expl_EI_BEF_Loco_ratio</th>\n",
       "      <th>Expl_E_TOT_Loco_ratio</th>\n",
       "      <th>Expl_I_TOT_Loco_ratio</th>\n",
       "      <th>Expl_E_I_TOT_Loco_ratio</th>\n",
       "      <th>Eff_Expl_E</th>\n",
       "      <th>Eff_Expl_I</th>\n",
       "      <th>Eff_Expl_EI</th>\n",
       "      <th>E_E</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LE2F1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>0_Autumn</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lisket</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>1.846154</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>Lisket_1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LE2F2_1</td>\n",
       "      <td>0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>0_Autumn</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lisket</td>\n",
       "      <td>...</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Lisket_1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LE2F3_1</td>\n",
       "      <td>0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>0_Autumn</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lisket</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Lisket_1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LE2F4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>0_Autumn</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lisket</td>\n",
       "      <td>...</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>4.214286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Lisket_1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LE2F1_2</td>\n",
       "      <td>0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>0_Autumn</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Lisket</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Lisket_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>Rat28</td>\n",
       "      <td>15</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>15_Winter</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "      <td>LE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>1.343750</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>LE_98_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>Rat11</td>\n",
       "      <td>15</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>15_Winter</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>LE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>LE_99_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>Rat12</td>\n",
       "      <td>15</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>15_Winter</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>LE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>1.653846</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>LE_99_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>Rat33</td>\n",
       "      <td>15</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>15_Winter</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>LE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.771429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>LE_99_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>Rat34</td>\n",
       "      <td>15</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>15_Winter</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>LE</td>\n",
       "      <td>...</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>1.558824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>LE_99_15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5368 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Animal  Generation  Season Separation        G_S  Paradigm  \\\n",
       "0     LE2F1_1           0  Autumn 2019-08-26   0_Autumn         1   \n",
       "1     LE2F2_1           0  Autumn 2019-08-26   0_Autumn         1   \n",
       "2     LE2F3_1           0  Autumn 2019-08-26   0_Autumn         2   \n",
       "3     LE2F4_1           0  Autumn 2019-08-26   0_Autumn         2   \n",
       "4     LE2F1_2           0  Autumn 2019-08-26   0_Autumn         1   \n",
       "...       ...         ...     ...        ...        ...       ...   \n",
       "5363    Rat28          15  Winter 2024-12-30  15_Winter         2   \n",
       "5364    Rat11          15  Winter 2024-12-30  15_Winter         1   \n",
       "5365    Rat12          15  Winter 2024-12-30  15_Winter         1   \n",
       "5366    Rat33          15  Winter 2024-12-30  15_Winter         2   \n",
       "5367    Rat34          15  Winter 2024-12-30  15_Winter         2   \n",
       "\n",
       "     Date_Ambitus  Year  NR   Group  ... Expl_I_BEF_Loco_ratio  \\\n",
       "0      2019-10-07     0   1  Lisket  ...              1.076923   \n",
       "1      2019-10-07     0   1  Lisket  ...              1.857143   \n",
       "2      2019-10-07     0   1  Lisket  ...              1.800000   \n",
       "3      2019-10-07     0   1  Lisket  ...              3.166667   \n",
       "4      2019-10-07     0   2  Lisket  ...              0.916667   \n",
       "...           ...   ...  ..     ...  ...                   ...   \n",
       "5363   2025-02-18     6  98      LE  ...              1.600000   \n",
       "5364   2025-02-18     6  99      LE  ...              0.520000   \n",
       "5365   2025-02-18     6  99      LE  ...              1.200000   \n",
       "5366   2025-02-18     6  99      LE  ...              1.750000   \n",
       "5367   2025-02-18     6  99      LE  ...              2.090909   \n",
       "\n",
       "     Expl_EI_BEF_Loco_ratio  Expl_E_TOT_Loco_ratio  Expl_I_TOT_Loco_ratio  \\\n",
       "0                  2.923077               1.846154               1.076923   \n",
       "1                  3.428571               1.500000               2.100000   \n",
       "2                  2.800000               0.769231               1.000000   \n",
       "3                  4.833333               1.857143               2.357143   \n",
       "4                  2.250000               1.333333               0.916667   \n",
       "...                     ...                    ...                    ...   \n",
       "5363               2.500000               0.968750               1.343750   \n",
       "5364               1.120000               0.600000               0.520000   \n",
       "5365               2.400000               0.846154               0.807692   \n",
       "5366               2.875000               0.971429               0.800000   \n",
       "5367               3.090909               0.764706               0.794118   \n",
       "\n",
       "      Expl_E_I_TOT_Loco_ratio  Eff_Expl_E  Eff_Expl_I  Eff_Expl_EI     E_E  \\\n",
       "0                    2.923077       1.000        0.75     0.875000  0.8750   \n",
       "1                    3.600000       1.000        1.00     1.000000  1.0000   \n",
       "2                    1.769231         NaN        1.00     0.533333  1.0000   \n",
       "3                    4.214286         NaN        1.00     0.500000  1.0000   \n",
       "4                    2.250000       1.000        1.00     1.000000  1.0000   \n",
       "...                       ...         ...         ...          ...     ...   \n",
       "5363                 2.312500         NaN        1.00     0.533333  1.0000   \n",
       "5364                 1.120000       0.875        1.00     0.937500  0.9375   \n",
       "5365                 1.653846       1.000        1.00     1.000000  1.0000   \n",
       "5366                 1.771429         NaN        1.00     0.533333  1.0000   \n",
       "5367                 1.558824         NaN        1.00     0.533333  1.0000   \n",
       "\n",
       "              id  \n",
       "0     Lisket_1_0  \n",
       "1     Lisket_1_0  \n",
       "2     Lisket_1_0  \n",
       "3     Lisket_1_0  \n",
       "4     Lisket_2_0  \n",
       "...          ...  \n",
       "5363    LE_98_15  \n",
       "5364    LE_99_15  \n",
       "5365    LE_99_15  \n",
       "5366    LE_99_15  \n",
       "5367    LE_99_15  \n",
       "\n",
       "[5368 rows x 105 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_data = pd.read_parquet(params['data'])\n",
    "parquet_data = gen_id(parquet_data)\n",
    "parquet_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce and Restructure Dataset\n",
    "To prepare the dataset for machine learning:\n",
    "- We remove unused metadata columns.\n",
    "- We restructure the data so that each rat is represented by a single row using make_rat_one_row().\n",
    "- (Optionally) We standardize feature names or values (e.g., converting % to \"perc\").\n",
    "\n",
    "This format is suitable for classical machine learning algorithms that expect tabular inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns based on the parameter list\n",
    "parquet_data = parquet_data.drop(columns=params['to_drop_cols'])\n",
    "# Transform the dataset so that each rat is represented by a single row\n",
    "one_rowed_data = make_rat_one_row(parquet_data)\n",
    "# Optionally standardize column names or values\n",
    "one_rowed_data = one_rowed_data.replace('male', 'Male')\n",
    "one_rowed_data = one_rowed_data.replace('female', 'Female')\n",
    "one_rowed_data = one_rowed_data.fillna(-1)\n",
    "one_rowed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Redundant or Non-Feature Columns\n",
    "We automatically remove columns that are not needed for machine learning, including:\n",
    "- Redundant group/gender/year fields (duplicated across time)\n",
    "- Intermediate or repeated trial-level metadata\n",
    "- Columns with placeholder names like Unnamed:\n",
    "\n",
    "This keeps only relevant, flat (one-row-per-animal) behavioral features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns that are not needed for the analysis\n",
    "columns_to_drop = one_rowed_data.filter(regex='Group_|Gender_|Season_|Trials_|NR_|Year_|Paradigm_|Generation_|Unnamed').columns\n",
    "one_rowed_data = one_rowed_data.drop(columns=columns_to_drop)\n",
    "#Drop columns that are only contains -1 values\n",
    "one_rowed_data = one_rowed_data.loc[:, (one_rowed_data != -1).any(axis=0)]\n",
    "one_rowed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Cleaned Dataset\n",
    "After removing the final unused column (Trials), we export the cleaned and restructured dataset to the processed/ directory.\n",
    "The filename includes the current date, allowing for versioning and traceability.\n",
    "\n",
    "Resulting file example:\n",
    " - ambitus_0_15_ml_ready_25-07-2025.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Trials' column if it's no longer relevant\n",
    "one_rowed_data.drop(columns=['Trials'], inplace=True)\n",
    "# Save the cleaned and flattened dataset to CSV with timestamp\n",
    "one_rowed_data.to_csv(f\"processed/ambitus_0_15_ml_ready_{datetime.datetime.now().strftime(\"%d-%M-%Y\")}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
